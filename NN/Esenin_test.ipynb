{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I7C0jyWxIhGE"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "!pip install datasets\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxG613ugPX-d"
      },
      "source": [
        "# Zero shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tEMJFNjI_YP"
      },
      "outputs": [],
      "source": [
        "# Загрузка предобученной модели\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXT4jf3IJCXw"
      },
      "outputs": [],
      "source": [
        "# Кандидатные категории\n",
        "categories = [\"Претензия\", \"Предложение\", \"Благодарность\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXXr0UJ2OV76"
      },
      "outputs": [],
      "source": [
        "# Текст для классификации\n",
        "text = [\"Сервис ужасный, товар доставили с опозданием.\",\n",
        "        \"Сервис отличный, товар доставили вовремя!\",\n",
        "        \"Сервис ужасный, мне ничего не понравилось, у меня к вас много претензий\",\n",
        "        \"Предлагаю вам улучшить качество обслуживания. Как вы смотрите на мои идеи и предложения сотрудничать?\",\n",
        "        \"Спасибо большое за такой сервис, я вам очень благодарен! Самый лучший сервис!\"]\n",
        "# Предсказание\n",
        "result = classifier(text, candidate_labels=categories)\n",
        "print(*[f'{res[\"labels\"]} : {[round(x, 3) for x in res[\"scores\"]]} <--- {res[\"sequence\"]}' for res in result], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoSz0SiFJaJc"
      },
      "outputs": [],
      "source": [
        "# Текст для классификации\n",
        "text = [\"Всё плохо\", \"Предлагаю идею\", \"Спасибо большое\"]\n",
        "# Предсказание\n",
        "result = classifier(text, candidate_labels=categories)\n",
        "print(*[f'{res[\"labels\"]} : {[round(x, 3) for x in res[\"scores\"]]} <--- {res[\"sequence\"]}' for res in result], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp2JmD5WN7lw"
      },
      "outputs": [],
      "source": [
        "# Текст для классификации\n",
        "text = categories\n",
        "# Предсказание\n",
        "result = classifier(text, candidate_labels=categories)\n",
        "print(*[f'{res[\"labels\"]} : {[round(x, 3) for x in res[\"scores\"]]} <--- {res[\"sequence\"]}' for res in result], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGa5p50sOMUk"
      },
      "outputs": [],
      "source": [
        "# Текст для классификации\n",
        "with open('./comment1.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "text = [input_text]\n",
        "\n",
        "# Предсказание\n",
        "result = classifier(text, candidate_labels=categories)\n",
        "print(*[f'{res[\"labels\"]} : {[round(x, 3) for x in res[\"scores\"]]} <--- {res[\"sequence\"]}' for res in result], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26FjbF0GRqgH"
      },
      "outputs": [],
      "source": [
        "# Текст для классификации\n",
        "with open('./comment2.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "text = [input_text]\n",
        "\n",
        "# Предсказание\n",
        "result = classifier(text, candidate_labels=categories)\n",
        "print(*[f'{res[\"labels\"]} : {[round(x, 3) for x in res[\"scores\"]]} <--- {res[\"sequence\"]}' for res in result], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCmJuvgBSSyz"
      },
      "outputs": [],
      "source": [
        "# Текст для классификации\n",
        "with open('./comment3.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "text = [input_text]\n",
        "\n",
        "# Предсказание\n",
        "result = classifier(text, candidate_labels=categories)\n",
        "print(*[f'{res[\"labels\"]} : {[round(x, 3) for x in res[\"scores\"]]} <--- {res[\"sequence\"]}' for res in result], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6E8btDQTAJM"
      },
      "outputs": [],
      "source": [
        "# Текст для классификации\n",
        "with open('./comment4.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "text = [input_text]\n",
        "\n",
        "# Предсказание\n",
        "result = classifier(text, candidate_labels=categories)\n",
        "print(*[f'{res[\"labels\"]} : {[round(x, 3) for x in res[\"scores\"]]} <--- {res[\"sequence\"]}' for res in result], sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqGBJLplPe5G"
      },
      "source": [
        "# ruBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW9-M6b7Php0"
      },
      "outputs": [],
      "source": [
        "# 1. Загрузка данных\n",
        "with open('./rubert_train_dataset.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "dataset = Dataset.from_dict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw7eHA9xRU2Q"
      },
      "outputs": [],
      "source": [
        "# 2. Загрузка предобученной модели и токенизатора\n",
        "model_name = \"DeepPavlov/rubert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7Dl-tiTRXnK"
      },
      "outputs": [],
      "source": [
        "# 3. Токенизация данных\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
        "\n",
        "# Деление на обучающую и валидационную выборки\n",
        "train_texts, eval_texts, train_labels, eval_labels = train_test_split(\n",
        "    data[\"text\"], data[\"labels\"], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Создание обучающего и валидационного датасетов\n",
        "train_dataset = Dataset.from_dict({\"text\": train_texts, \"labels\": train_labels})\n",
        "eval_dataset = Dataset.from_dict({\"text\": eval_texts, \"labels\": eval_labels})\n",
        "\n",
        "# Токенизация данных\n",
        "train_encoded = train_dataset.map(preprocess_function, batched=True)\n",
        "eval_encoded = eval_dataset.map(preprocess_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g2qxCdhRm65"
      },
      "outputs": [],
      "source": [
        "# 4. Настройка параметров обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",         # Папка для результатов\n",
        "    evaluation_strategy=\"epoch\",    # Оценка раз в эпоху\n",
        "    learning_rate=2e-5,             # Скорость обучения\n",
        "    per_device_train_batch_size=16, # Размер батча\n",
        "    num_train_epochs=10,            # Увеличиваем количество эпох\n",
        "    weight_decay=0.01,              # Регуляризация\n",
        "    save_strategy=\"epoch\",          # Сохранение модели раз в эпоху\n",
        "    logging_dir='./logs',           # Логи\n",
        "    logging_steps=10,               # Частота логов\n",
        ")\n",
        "\n",
        "# 5. Создание Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_encoded,\n",
        "    eval_dataset=eval_encoded  # Валидационный датасет\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBk60BVERsSj"
      },
      "outputs": [],
      "source": [
        "# 6. Запуск обучения\n",
        "trainer.train()\n",
        "\n",
        "# 7. Сохранение модели\n",
        "model.save_pretrained(\"./drive/MyDrive/Esenin colab/finetuned_rubert\")\n",
        "tokenizer.save_pretrained(\"./drive/MyDrive/Esenin colab/finetuned_rubert\")\n",
        "# model.save_pretrained(\"./finetuned_rubert\")\n",
        "# tokenizer.save_pretrained(\"./finetuned_rubert\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot a graph of loss of trainer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the training history in the 'trainer' object\n",
        "# Access the training logs (replace with the correct attribute if necessary)\n",
        "if hasattr(trainer, 'state'):\n",
        "  if hasattr(trainer.state, 'log_history'):\n",
        "    log_history = trainer.state.log_history\n",
        "    epochs = [log['epoch'] for log in log_history if 'epoch' in log]\n",
        "    train_losses = [log['loss'] for log in log_history if 'loss' in log and 'eval_loss' not in log]\n",
        "    eval_losses = [log['eval_loss'] for log in log_history if 'eval_loss' in log]\n",
        "\n",
        "    # Plotting training and eval loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
        "    plt.plot(epochs, eval_losses, label=\"Evaluation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training and Evaluation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "  else:\n",
        "    print(\"Log history not found in trainer.state\")\n",
        "else:\n",
        "  print(\"State attribute not found in the trainer object\")"
      ],
      "metadata": {
        "id": "nxZvhUt8qxyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot a graph of following data:\n",
        "# 1   0.702900\t0.412326\n",
        "# 2\t0.152200\t0.082027\n",
        "# 3\t0.021600\t0.012879\n",
        "# 4\t0.008200\t0.011686\n",
        "# 5\t0.005200\t0.004955\n",
        "# 6\t0.004100\t0.004149\n",
        "# 7\t0.003500\t0.003836\n",
        "# 8\t0.003100\t0.003733\n",
        "# 9\t0.002900\t0.003627\n",
        "# 10\t0.002700\t0.003622\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "y1 = [0.702900, 0.152200, 0.021600, 0.008200, 0.005200, 0.004100, 0.003500, 0.003100, 0.002900, 0.002700]\n",
        "y2 = [0.412326, 0.082027, 0.012879, 0.011686, 0.004955, 0.004149, 0.003836, 0.003733, 0.003627, 0.003622]\n",
        "\n",
        "# Plotting\n",
        "plt.plot(x, y1, label=\"Training Loss\")\n",
        "plt.plot(x, y2, label=\"Validation Loss\")\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bqBYojlPrP8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFIhrcF4YlmX"
      },
      "outputs": [],
      "source": [
        "# 8. Получение предсказаний на валидационном наборе\n",
        "predictions = trainer.predict(eval_encoded)  # Используем eval_encoded\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Настоящие метки из eval_dataset\n",
        "true_labels = eval_dataset[\"labels\"]\n",
        "\n",
        "# 9. Оценка качества классификации\n",
        "print(classification_report(\n",
        "    true_labels,\n",
        "    predicted_labels,\n",
        "    target_names=[\"Претензия\", \"Предложение\", \"Благодарность\"],\n",
        "    zero_division=0\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgI_sQZpjvjh"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Подсчет примеров в каждой категории\n",
        "print(Counter(train_dataset[\"labels\"]))\n",
        "print(Counter(predicted_labels))\n",
        "probabilities = predictions.predictions  # Вероятности для каждого класса\n",
        "print(probabilities[:5])  # Посмотреть первые 5 строк"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IE0_VupkSAp"
      },
      "outputs": [],
      "source": [
        "incorrect_predictions = [\n",
        "    (true, pred, text)\n",
        "    for true, pred, text in zip(true_labels, predicted_labels, eval_texts)\n",
        "    if true != pred\n",
        "]\n",
        "for true, pred, text in incorrect_predictions:\n",
        "    print(f\"True: {true}, Predicted: {pred}, Text: {text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMtg2h4f4nSJ"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Загрузка обученной модели и токенизатора\n",
        "model_path = \"./drive/MyDrive/Esenin colab/finetuned_rubert\"  # Путь к вашей обученной модели\n",
        "classifier = pipeline(\"text-classification\", model=model_path, tokenizer=model_path)\n",
        "\n",
        "# Пример использования\n",
        "def classify_feedback(feedbacks):\n",
        "    \"\"\"\n",
        "    Классификация списка отзывов по категориям.\n",
        "    :param feedbacks: List[str] - Список текстов отзывов\n",
        "    :return: List[Dict] - Список классификаций с вероятностями\n",
        "    \"\"\"\n",
        "    results = classifier(feedbacks)\n",
        "    return [\n",
        "        {\n",
        "            \"text\": feedback,\n",
        "            \"label\": result[\"label\"],\n",
        "            \"score\": round(result[\"score\"], 2)  # Удобное округление вероятности\n",
        "        }\n",
        "        for feedback, result in zip(feedbacks, results)\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример отзывов\n",
        "with open('./comment1.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "feedbacks = [input_text]\n",
        "with open('./comment2.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "feedbacks.append(input_text)\n",
        "with open('./comment3.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "feedbacks.append(input_text)\n",
        "with open('./comment4.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "feedbacks.append(input_text)\n",
        "with open('./comment5.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "feedbacks.append(input_text)\n",
        "with open('./comment6.txt', 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()\n",
        "feedbacks.append(input_text)\n",
        "\n",
        "# Классификация отзывов\n",
        "classified_feedbacks = classify_feedback(feedbacks)\n",
        "\n",
        "# Печать результатов\n",
        "for feedback in classified_feedbacks:\n",
        "    print(f\"Отзыв: {feedback['text']}\")\n",
        "    print(f\"Категория: {feedback['label']}, Уверенность: {feedback['score']}\\n\")\n"
      ],
      "metadata": {
        "id": "5uDDEL2-jq2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "5a1-KPDJgwt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(json_data):\n",
        "    text = json_data['text'].replace('\\n', ' ')\n",
        "    text = text.replace('\\r', ' ')\n",
        "    text = text.replace('<p>', '')\n",
        "    text = text.replace('</p>', '')\n",
        "    text = text.replace('<ul>', '')\n",
        "    text = text.replace('<li>', '')\n",
        "    while '  ' in text:\n",
        "        text = text.replace('  ', ' ')\n",
        "    text = text.strip()\n",
        "    if len(text) > 512:\n",
        "        text = text[:512]\n",
        "    return text"
      ],
      "metadata": {
        "id": "dWMGwjdHgvGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_data(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as file:\n",
        "            json_data = json.load(file)\n",
        "            return json_data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filepath}' not found.\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Invalid JSON format in '{filepath}'.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Xb7WpLgmgzv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "json_data = load_json_data('./drive/MyDrive/Esenin colab/finetuned_rubert/reviews_bankiru_promsvyazbank.json')\n",
        "if json_data:\n",
        "    print(preprocessing(json_data[0]))"
      ],
      "metadata": {
        "id": "YbilPCQuiIGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data[0]"
      ],
      "metadata": {
        "id": "GzY5uiN3SJxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: get the texts from json_data with preprocessing and pass them to classify_feedback. Print the output correspondingly for feedback['label']: LABEL_0 is \"Претензия\", LABEL_1 is \"Предложение\", LABEL_2 is \"Благодарность\"\n",
        "\n",
        "LABEL_0 = \"Претензия\"\n",
        "LABEL_1 = \"Предложение\"\n",
        "LABEL_2 = \"Благодарность\"\n",
        "\n",
        "# Example usage\n",
        "# json_data = load_json_data('./drive/MyDrive/Esenin colab/finetuned_rubert/reviews_bankiru_promsvyazbank.json')\n",
        "json_data = load_json_data('./drive/MyDrive/Esenin colab/real_feedback123.json')\n",
        "result = []\n",
        "# json_data = json_data[:100] # !@#%!#$%!#%#$%#@$%!#!#$!%!#$%!#\n",
        "texts_to_classify = []\n",
        "for item in json_data:\n",
        "    texts_to_classify.append(preprocessing(item))\n",
        "\n",
        "classified_feedbacks = classify_feedback(texts_to_classify)\n",
        "\n",
        "resmet = []\n",
        "for feedback, item in zip(classified_feedbacks, json_data):\n",
        "    label_mapping = {\n",
        "        \"LABEL_0\": LABEL_0,\n",
        "        \"LABEL_1\": LABEL_1,\n",
        "        \"LABEL_2\": LABEL_2\n",
        "    }\n",
        "    resmet.append(label_mapping.get(feedback['label'], 'Unknown'))\n",
        "    # result.append({\n",
        "    #     'grade': item['grade'],\n",
        "    #     'dateCreate': item['dateCreate'],\n",
        "    #     'label': label_mapping.get(feedback['label'], 'Unknown')})\n",
        "    # print(f\"Отзыв: {feedback['text']}\")\n",
        "    # print(f\"Категория: {label_mapping.get(feedback['label'], 'Unknown')}, Уверенность: {feedback['score']}\\n\")\n"
      ],
      "metadata": {
        "id": "gHhcnK0vilsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: compare predicted `resmet` values and the truth values from `json_data['label']`. Compute the accuracy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming 'resmet' and 'json_data' are defined as in the previous code\n",
        "\n",
        "true_labels = [item['label'] for item in json_data]\n",
        "accuracy = accuracy_score(true_labels, resmet)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "5vfx_QsLeMsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/Esenin colab/labeled_reviews.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(result, f, ensure_ascii=False, indent=4)\n"
      ],
      "metadata": {
        "id": "WiH91K8LV6m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syYi4mDmLNWF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}